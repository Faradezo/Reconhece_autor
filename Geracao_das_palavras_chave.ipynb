{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1203ec5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in c:\\users\\faradezo\\anaconda3\\lib\\site-packages (1.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Faradezo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\Faradezo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode\n",
    "\n",
    "import glob, os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from unidecode import unidecode\n",
    "import string\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "518fc383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files(folder):\n",
    "    file_list = []\n",
    "    if os.path.exists(folder):\n",
    "        for root, dirs, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                file_list.append(os.path.join(root,file))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ce412cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_stop_words(df_col):\n",
    "    #Faz a contagem de palavras por cada linha do artigo\n",
    "    df_col['words'] = df_col['texto'].str.split().str.len()\n",
    "    \n",
    "    #Elimina qualquer artigo que tenha gerado menos de 100 palavras\n",
    "    df_col = df_col.loc[(df_col['words'] > 100)]\n",
    "    \n",
    "    stop = stopwords.words('portuguese')\n",
    "    # stop.append('nao')\n",
    "    stop2 = list()\n",
    "    for word in stop:\n",
    "        stop2.append(unidecode(word))\n",
    "    \n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    # remoção de palavras de parada\n",
    "    #df_col['texto_tratado'] = df_col['texto'].apply(lambda x: [item for item in x if item not in stop])\n",
    "    df_col['texto_tratado'] = df_col['texto'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "    #Transforma em minuscula e remoção de acentos \n",
    "    df_col['texto_tratado'] = df_col['texto_tratado'].str.lower().apply(lambda x: unidecode(x))\n",
    "    # remocação de pontuaçao\n",
    "    df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
    "    # remocação de numeros\n",
    "    df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.digits), '')\n",
    "    # remoção de palavras de parada (repescagem)\n",
    "    df_col['texto_tratado'] = df_col['texto_tratado'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop2)]))\n",
    "    \n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    XCOL = vectorizer.fit_transform(df_col['texto_tratado'])\n",
    "    vocabulary_col = vectorizer.get_feature_names()\n",
    "    pdXCOL = pd.DataFrame(data=XCOL.toarray(), columns=vocabulary_col) #.iloc[:,0::2]\n",
    "    \n",
    "    \n",
    "    df_XCOL = pdXCOL.T\n",
    "    df_XCOL['total'] = df_XCOL.sum(axis=1) \n",
    "    \n",
    "    # Transpoe a matriz para que as palavras fiquem como linhas, e cada documento como uma linha\n",
    "    df_XCOL = pdXCOL.T\n",
    "    \n",
    "    #Calcula a quantidade de vezes que cada palavra é utilizada\n",
    "    df_XCOL['total'] = df_XCOL.sum(axis=1)\n",
    "    \n",
    "    #Remove as colunas individuais de cada documento para gerar a tabela\n",
    "    df_XCOL.drop(df_XCOL.columns[0:len(df_col['texto'])], axis=1, inplace=True)\n",
    "    \n",
    "    #Ordena o resultado final\n",
    "    df_XCOL = df_XCOL.sort_values(by='total', ascending=False)\n",
    "    #return df_XCOL <- até aqui tava indo\n",
    "    \n",
    "    n_words = 30\n",
    "    \n",
    "    # Transpoe a matriz para que as palavras fiquem como linhas, e cada documento como uma linha\n",
    "    pdXCOLT = pdXCOL.T\n",
    "    \n",
    "    #Mantem o percentual de frequencia de uso para comparação\n",
    "    pdXCOLT['presente'] = (pdXCOLT.ne(0).sum(axis=1) -1) / len(df_col['texto'])\n",
    "    \n",
    "    #Ordena\n",
    "    pdXCOLT = pdXCOLT.sort_values(by='presente', ascending=False)\n",
    "    \n",
    "    #Mantem so as 30 primeiras palavras\n",
    "    pdXCOLT = pdXCOLT.head(n_words)\n",
    "    \n",
    "    # Apaga todas as clunas, exceto a com as palavras\n",
    "    pdXCOLT.drop(pdXCOLT.columns[0:], axis=1, inplace=True)\n",
    "    \n",
    "    # Apaga todas as clunas, exceto a com as porcentagens presente\n",
    "    #pdXCOLT.drop(pdXCOLT.columns[0:-1], axis=1, inplace=True)\n",
    "    \n",
    "    #gera o dicionario com o saco de palavras\n",
    "    #ret = {}\n",
    "    #for sac in pdXCOLT.to_dict().values():\n",
    "    #    print(sac)\n",
    "    #    ret = sac\n",
    "\n",
    "    return pdXCOLT#ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d3ac89eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variavel com o nome de todos os arquivos json dos colunistas q estao salvos\n",
    "colunistas = get_all_files('textos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee08788d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['textos\\\\alexandre_garcia.json',\n",
       " 'textos\\\\arnaldo_jabor.json',\n",
       " 'textos\\\\Carla_Araujo.json',\n",
       " 'textos\\\\Josias_de_Souza.json',\n",
       " 'textos\\\\Juca_Kfouri.json',\n",
       " 'textos\\\\Kennedy_Alencar.json',\n",
       " 'textos\\\\Leonardo_Sakamoto.json',\n",
       " 'textos\\\\Mauricio_Stycer.json',\n",
       " 'textos\\\\Reinaldo_Azevedo.json',\n",
       " 'textos\\\\Ricardo_Kotscho.json',\n",
       " 'textos\\\\Tales_Faria.json',\n",
       " 'textos\\\\Thays_Oyama.json',\n",
       " 'textos\\\\Walter_Maierovitch.json']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colunistas = get_all_files('textos')\n",
    "#colunistas = colunistas[0]\n",
    "#colunistas\n",
    "#colunistas = colunistas[:1]\n",
    "colunistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5117e0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexandre_garcia\n"
     ]
    }
   ],
   "source": [
    "for enu, colunista in enumerate(colunistas):\n",
    "    print(colunista[7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c6c9aeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alexandre_garcia': ['presidente',\n",
       "  'pais',\n",
       "  'anos',\n",
       "  'ainda',\n",
       "  'ser',\n",
       "  'agora',\n",
       "  'porque',\n",
       "  'sobre',\n",
       "  'vai',\n",
       "  'brasil',\n",
       "  'poder',\n",
       "  'contra',\n",
       "  'todos',\n",
       "  'ano',\n",
       "  'bolsonaro',\n",
       "  'governo',\n",
       "  'ter',\n",
       "  'maior',\n",
       "  'pode',\n",
       "  'assim',\n",
       "  'povo',\n",
       "  'semana',\n",
       "  'constituicao',\n",
       "  'quase',\n",
       "  'lei',\n",
       "  'brasileiros',\n",
       "  'milhoes',\n",
       "  'apenas',\n",
       "  'ministro',\n",
       "  'corrupcao'],\n",
       " 'arnaldo_jabor': ['tudo',\n",
       "  'ser',\n",
       "  'hoje',\n",
       "  'grande',\n",
       "  'mundo',\n",
       "  'vida',\n",
       "  'anos',\n",
       "  'pois',\n",
       "  'sempre',\n",
       "  'bem',\n",
       "  'nada',\n",
       "  'porque',\n",
       "  'pais',\n",
       "  'sobre',\n",
       "  'contra',\n",
       "  'ainda',\n",
       "  'assim',\n",
       "  'outro',\n",
       "  'onde',\n",
       "  'dia',\n",
       "  'agora',\n",
       "  'brasil',\n",
       "  'nunca',\n",
       "  'todos',\n",
       "  'tempo',\n",
       "  'politica',\n",
       "  'vez',\n",
       "  'diante',\n",
       "  'coisa',\n",
       "  'vai'],\n",
       " 'Carla_Araujo': ['presidente',\n",
       "  'bolsonaro',\n",
       "  'jair',\n",
       "  'ministro',\n",
       "  'feira',\n",
       "  'governo',\n",
       "  'nesta',\n",
       "  'economia',\n",
       "  'paulo',\n",
       "  'guedes',\n",
       "  'disse',\n",
       "  'coluna',\n",
       "  'federal',\n",
       "  'ministerio',\n",
       "  'afirmou',\n",
       "  'brasil',\n",
       "  'ainda',\n",
       "  'vai',\n",
       "  'tribunal',\n",
       "  'camara',\n",
       "  'congresso',\n",
       "  'segunda',\n",
       "  'ser',\n",
       "  'decisao',\n",
       "  'emergencial',\n",
       "  'sobre',\n",
       "  'apos',\n",
       "  'ter',\n",
       "  'economica',\n",
       "  'segundo'],\n",
       " 'Josias_de_Souza': ['bolsonaro',\n",
       "  'presidente',\n",
       "  'ser',\n",
       "  'sobre',\n",
       "  'ministro',\n",
       "  'contra',\n",
       "  'governo',\n",
       "  'brasil',\n",
       "  'covid',\n",
       "  'federal',\n",
       "  'supremo',\n",
       "  'pandemia',\n",
       "  'cpi',\n",
       "  'disse',\n",
       "  'ainda',\n",
       "  'republica',\n",
       "  'saude',\n",
       "  'ministerio',\n",
       "  'planalto',\n",
       "  'tribunal',\n",
       "  'capitao',\n",
       "  'pais',\n",
       "  'pode',\n",
       "  'feira',\n",
       "  'dois',\n",
       "  'ter',\n",
       "  'apenas',\n",
       "  'tres',\n",
       "  'fazer',\n",
       "  'politica'],\n",
       " 'Juca_Kfouri': ['jogo',\n",
       "  'porque',\n",
       "  'tempo',\n",
       "  'gol',\n",
       "  'ser',\n",
       "  'segundo',\n",
       "  'primeiro',\n",
       "  'dois',\n",
       "  'contra',\n",
       "  'fez',\n",
       "  'minutos',\n",
       "  'time',\n",
       "  'futebol',\n",
       "  'ainda',\n",
       "  'paulo',\n",
       "  'jogos',\n",
       "  'bola',\n",
       "  'fazer',\n",
       "  'brasil',\n",
       "  'tres',\n",
       "  'flamengo',\n",
       "  'assim',\n",
       "  'vez',\n",
       "  'ter',\n",
       "  'apenas',\n",
       "  'melhor',\n",
       "  'lugar',\n",
       "  'deu',\n",
       "  'bem',\n",
       "  'menos'],\n",
       " 'Kennedy_Alencar': ['presidente',\n",
       "  'bolsonaro',\n",
       "  'brasil',\n",
       "  'ser',\n",
       "  'pais',\n",
       "  'sobre',\n",
       "  'contra',\n",
       "  'jair',\n",
       "  'governo',\n",
       "  'trump',\n",
       "  'hoje',\n",
       "  'ter',\n",
       "  'disse',\n",
       "  'politica',\n",
       "  'ouca',\n",
       "  'donald',\n",
       "  'estados',\n",
       "  'federal',\n",
       "  'ministro',\n",
       "  'pode',\n",
       "  'eua',\n",
       "  'pandemia',\n",
       "  'segundo',\n",
       "  'comentario',\n",
       "  'porque',\n",
       "  'estado',\n",
       "  'republica',\n",
       "  'ex',\n",
       "  'fim',\n",
       "  'maior'],\n",
       " 'Leonardo_Sakamoto': ['bolsonaro',\n",
       "  'presidente',\n",
       "  'governo',\n",
       "  'ser',\n",
       "  'jair',\n",
       "  'federal',\n",
       "  'brasil',\n",
       "  'covid',\n",
       "  'ter',\n",
       "  'nesta',\n",
       "  'ano',\n",
       "  'pandemia',\n",
       "  'sobre',\n",
       "  'pessoas',\n",
       "  'contra',\n",
       "  'pais',\n",
       "  'parte',\n",
       "  'dia',\n",
       "  'pode',\n",
       "  'porque',\n",
       "  'apos',\n",
       "  'apenas',\n",
       "  'afirmou',\n",
       "  'nacional',\n",
       "  'ainda',\n",
       "  'forma',\n",
       "  'vai',\n",
       "  'populacao',\n",
       "  'disse',\n",
       "  'conta'],\n",
       " 'Mauricio_Stycer': ['sobre',\n",
       "  'feira',\n",
       "  'programa',\n",
       "  'ser',\n",
       "  'globo',\n",
       "  'ainda',\n",
       "  'disse',\n",
       "  'nesta',\n",
       "  'ter',\n",
       "  'apos',\n",
       "  'publico',\n",
       "  'vai',\n",
       "  'emissora',\n",
       "  'brasil',\n",
       "  'tv',\n",
       "  'segundo',\n",
       "  'momento',\n",
       "  'bbb',\n",
       "  'dois',\n",
       "  'apresentador',\n",
       "  'anos',\n",
       "  'bem',\n",
       "  'fez',\n",
       "  'todos',\n",
       "  'dia',\n",
       "  'desta',\n",
       "  'tres',\n",
       "  'final',\n",
       "  'forma',\n",
       "  'neste'],\n",
       " 'Reinaldo_Azevedo': ['presidente',\n",
       "  'bolsonaro',\n",
       "  'ser',\n",
       "  'ainda',\n",
       "  'jair',\n",
       "  'contra',\n",
       "  'caso',\n",
       "  'sobre',\n",
       "  'pode',\n",
       "  'governo',\n",
       "  'porque',\n",
       "  'bem',\n",
       "  'claro',\n",
       "  'ministro',\n",
       "  'vai',\n",
       "  'entao',\n",
       "  'assim',\n",
       "  'dizer',\n",
       "  'segundo',\n",
       "  'pais',\n",
       "  'ter',\n",
       "  'ai',\n",
       "  'coisa',\n",
       "  'menos',\n",
       "  'hoje',\n",
       "  'supremo',\n",
       "  'brasil',\n",
       "  'fazer',\n",
       "  'agora',\n",
       "  'integra'],\n",
       " 'Ricardo_Kotscho': ['vida',\n",
       "  'segue',\n",
       "  'presidente',\n",
       "  'bolsonaro',\n",
       "  'governo',\n",
       "  'agora',\n",
       "  'ser',\n",
       "  'ainda',\n",
       "  'pais',\n",
       "  'brasil',\n",
       "  'pandemia',\n",
       "  'dia',\n",
       "  'tudo',\n",
       "  'todos',\n",
       "  'sobre',\n",
       "  'contra',\n",
       "  'vez',\n",
       "  'vai',\n",
       "  'feira',\n",
       "  'ter',\n",
       "  'hoje',\n",
       "  'pode',\n",
       "  'fazer',\n",
       "  'paulo',\n",
       "  'onde',\n",
       "  'tempo',\n",
       "  'anos',\n",
       "  'apenas',\n",
       "  'ministro',\n",
       "  'semana'],\n",
       " 'Tales_Faria': ['presidente',\n",
       "  'bolsonaro',\n",
       "  'governo',\n",
       "  'jair',\n",
       "  'ministro',\n",
       "  'contra',\n",
       "  'disse',\n",
       "  'camara',\n",
       "  'ser',\n",
       "  'congresso',\n",
       "  'republica',\n",
       "  'ex',\n",
       "  'ainda',\n",
       "  'agora',\n",
       "  'paulo',\n",
       "  'deputado',\n",
       "  'sobre',\n",
       "  'segundo',\n",
       "  'federal',\n",
       "  'dem',\n",
       "  'feira',\n",
       "  'planalto',\n",
       "  'pode',\n",
       "  'partido',\n",
       "  'blog',\n",
       "  'hoje',\n",
       "  'ter',\n",
       "  'lider',\n",
       "  'senado',\n",
       "  'rodrigo'],\n",
       " 'Thays_Oyama': ['presidente',\n",
       "  'bolsonaro',\n",
       "  'ex',\n",
       "  'jair',\n",
       "  'governo',\n",
       "  'ministro',\n",
       "  'ser',\n",
       "  'hoje',\n",
       "  'ter',\n",
       "  'sobre',\n",
       "  'agora',\n",
       "  'capitao',\n",
       "  'contra',\n",
       "  'pode',\n",
       "  'apenas',\n",
       "  'vez',\n",
       "  'ainda',\n",
       "  'federal',\n",
       "  'brasil',\n",
       "  'ontem',\n",
       "  'disse',\n",
       "  'caso',\n",
       "  'menos',\n",
       "  'paulo',\n",
       "  'republica',\n",
       "  'segundo',\n",
       "  'ano',\n",
       "  'bem',\n",
       "  'assim',\n",
       "  'parte'],\n",
       " 'Walter_Maierovitch': ['presidente',\n",
       "  'pano',\n",
       "  'rapido',\n",
       "  'republica',\n",
       "  'brasil',\n",
       "  'outro',\n",
       "  'bolsonaro',\n",
       "  'ter',\n",
       "  'supremo',\n",
       "  'ministro',\n",
       "  'federal',\n",
       "  'politica',\n",
       "  'onde',\n",
       "  'ainda',\n",
       "  'ser',\n",
       "  'tribunal',\n",
       "  'lei',\n",
       "  'ministros',\n",
       "  'apenas',\n",
       "  'poder',\n",
       "  'contra',\n",
       "  'caso',\n",
       "  'constitucional',\n",
       "  'sobre',\n",
       "  'governo',\n",
       "  'constituicao',\n",
       "  'politico',\n",
       "  'tempo',\n",
       "  'stf',\n",
       "  'usar']}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7abdcbcb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_1516/3207719678.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_col['texto_tratado'] = df_col['texto'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_1516/3207719678.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_col['texto_tratado'] = df_col['texto_tratado'].str.lower().apply(lambda x: unidecode(x))\n",
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_1516/3207719678.py:22: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_1516/3207719678.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_1516/3207719678.py:24: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.digits), '')\n",
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_1516/3207719678.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.digits), '')\n",
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_1516/3207719678.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_col['texto_tratado'] = df_col['texto_tratado'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop2)]))\n"
     ]
    }
   ],
   "source": [
    "sdp = {}\n",
    "for enu, colunista in enumerate(colunistas):\n",
    "    link = (f'https://raw.githubusercontent.com/Faradezo/Reconhece_autor/main/textos/{colunista[7:]}')#{colunista[7:]}')\n",
    "    df_col = pd.read_json(link)\n",
    "    b = get_all_stop_words(df_col)\n",
    "    if colunista[7:-5] not in sdp.keys():\n",
    "        sdp[colunista[7:-5]] = b.T.columns.tolist()\n",
    "sdp_file = open(\"sdp.pkl\", \"wb\")\n",
    "pickle.dump(sdp, sdp_file)\n",
    "sdp_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82e83ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col = pd.read_json('https://raw.githubusercontent.com/Faradezo/Reconhece_autor/main/textos/arnaldo_jabor.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2270c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bcda863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_6264/719350261.py:19: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_6264/719350261.py:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.digits), '')\n"
     ]
    }
   ],
   "source": [
    "#Faz a contagem de palavras por cada linha do artigo\n",
    "df_col['words'] = df_col['texto'].str.split().str.len()\n",
    "\n",
    "#Elimina qualquer artigo que tenha gerado menos de 100 palavras\n",
    "df_col = df_col.loc[(df_col['words'] > 100)]\n",
    "\n",
    "stop = stopwords.words('portuguese')\n",
    "# stop.append('nao')\n",
    "stop2 = list()\n",
    "for word in stop:\n",
    "  stop2.append(unidecode(word))\n",
    "  \n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "# remoção de palavras de parada\n",
    "df_col['texto_tratado'] = df_col['texto'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "#Transforma em minuscula e remoção de acentos \n",
    "df_col['texto_tratado'] = df_col['texto_tratado'].str.lower().apply(lambda x: unidecode(x))\n",
    "# remocação de pontuaçao              precisa corrigir \n",
    "df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
    "# remocação de numeros                precisa corrigir\n",
    "df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.digits), '')\n",
    "# remoção de palavras de parada (repescagem)\n",
    "df_col['texto_tratado'] = df_col['texto_tratado'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a3752534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04efbd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# vectorizer = TfidfVectorizer()\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "#Arnaldo Jabor\n",
    "XCOL = vectorizer.fit_transform(df_col['texto_tratado'])\n",
    "vocabulary_col = vectorizer.get_feature_names()\n",
    "pdXCOL = pd.DataFrame(data=XCOL.toarray(), columns=vocabulary_col) #.iloc[:,0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d86df975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_XCOL = pdXCOL.T\n",
    "df_XCOL['total'] = df_XCOL.sum(axis=1) \n",
    "\n",
    "# Transpoe a matriz para que as palavras fiquem como linhas, e cada documento como uma linha\n",
    "df_XCOL = pdXCOL.T\n",
    "\n",
    "#Calcula a quantidade de vezes que cada palavra é utilizada\n",
    "df_XCOL['total'] = df_XCOL.sum(axis=1)\n",
    "\n",
    "#Remove as colunas individuais de cada documento para gerar a tabela\n",
    "df_XCOL.drop(df_XCOL.columns[0:len(df_col['texto'])], axis=1, inplace=True)\n",
    "\n",
    "#Ordena o resultado final\n",
    "df_XCOL = df_XCOL.sort_values(by='total', ascending=False)\n",
    "\n",
    "#Gera a tabela\n",
    "#df_XCOL.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a88af8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 30\n",
    "\n",
    "# Transpoe a matriz para que as palavras fiquem como linhas, e cada documento como uma linha\n",
    "pdXCOLT = pdXCOL.T\n",
    "\n",
    "#Mantem o percentual de frequencia de uso para comparação\n",
    "pdXCOLT['presente'] = (pdXCOLT.ne(0).sum(axis=1) -1) / len(df_col['texto'])\n",
    "\n",
    "#Ordena\n",
    "pdXCOLT = pdXCOLT.sort_values(by='presente', ascending=False)\n",
    "\n",
    "#Mantem so as 30 primeiras palavras\n",
    "pdXCOLT = pdXCOLT.head(n_words)\n",
    "\n",
    "# Apaga todas as clunas, pois so queremos manter o indice para avaliar os demais textos\n",
    "pdXCOLT.drop(pdXCOLT.columns[0:424], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43e4f5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>presente</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tudo</th>\n",
       "      <td>0.886792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ser</th>\n",
       "      <td>0.813679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoje</th>\n",
       "      <td>0.811321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grande</th>\n",
       "      <td>0.766509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mundo</th>\n",
       "      <td>0.766509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vida</th>\n",
       "      <td>0.764151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anos</th>\n",
       "      <td>0.745283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pois</th>\n",
       "      <td>0.726415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sempre</th>\n",
       "      <td>0.705189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bem</th>\n",
       "      <td>0.700472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nada</th>\n",
       "      <td>0.688679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>porque</th>\n",
       "      <td>0.648585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pais</th>\n",
       "      <td>0.643868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sobre</th>\n",
       "      <td>0.639151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contra</th>\n",
       "      <td>0.627358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ainda</th>\n",
       "      <td>0.601415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assim</th>\n",
       "      <td>0.589623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outro</th>\n",
       "      <td>0.584906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onde</th>\n",
       "      <td>0.582547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dia</th>\n",
       "      <td>0.580189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agora</th>\n",
       "      <td>0.577830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brasil</th>\n",
       "      <td>0.568396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nunca</th>\n",
       "      <td>0.568396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>todos</th>\n",
       "      <td>0.563679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempo</th>\n",
       "      <td>0.561321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politica</th>\n",
       "      <td>0.556604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vez</th>\n",
       "      <td>0.547170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diante</th>\n",
       "      <td>0.544811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coisa</th>\n",
       "      <td>0.542453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vai</th>\n",
       "      <td>0.537736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          presente\n",
       "tudo      0.886792\n",
       "ser       0.813679\n",
       "hoje      0.811321\n",
       "grande    0.766509\n",
       "mundo     0.766509\n",
       "vida      0.764151\n",
       "anos      0.745283\n",
       "pois      0.726415\n",
       "sempre    0.705189\n",
       "bem       0.700472\n",
       "nada      0.688679\n",
       "porque    0.648585\n",
       "pais      0.643868\n",
       "sobre     0.639151\n",
       "contra    0.627358\n",
       "ainda     0.601415\n",
       "assim     0.589623\n",
       "outro     0.584906\n",
       "onde      0.582547\n",
       "dia       0.580189\n",
       "agora     0.577830\n",
       "brasil    0.568396\n",
       "nunca     0.568396\n",
       "todos     0.563679\n",
       "tempo     0.561321\n",
       "politica  0.556604\n",
       "vez       0.547170\n",
       "diante    0.544811\n",
       "coisa     0.542453\n",
       "vai       0.537736"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdXCOLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "799b6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sdp = {} #saco de palavras\n",
    "sdp = pdXCOLT.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8963e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sdp.values():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b24a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sac in pdXCOLT.to_dict().values():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1c8ae07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tudo': 0.8867924528301887,\n",
       " 'ser': 0.8136792452830188,\n",
       " 'hoje': 0.8113207547169812,\n",
       " 'grande': 0.7665094339622641,\n",
       " 'mundo': 0.7665094339622641,\n",
       " 'vida': 0.7641509433962265,\n",
       " 'anos': 0.7452830188679245,\n",
       " 'pois': 0.7264150943396226,\n",
       " 'sempre': 0.7051886792452831,\n",
       " 'bem': 0.7004716981132075,\n",
       " 'nada': 0.6886792452830188,\n",
       " 'porque': 0.6485849056603774,\n",
       " 'pais': 0.6438679245283019,\n",
       " 'sobre': 0.6391509433962265,\n",
       " 'contra': 0.6273584905660378,\n",
       " 'ainda': 0.6014150943396226,\n",
       " 'assim': 0.589622641509434,\n",
       " 'outro': 0.5849056603773585,\n",
       " 'onde': 0.5825471698113207,\n",
       " 'dia': 0.5801886792452831,\n",
       " 'agora': 0.5778301886792453,\n",
       " 'brasil': 0.5683962264150944,\n",
       " 'nunca': 0.5683962264150944,\n",
       " 'todos': 0.5636792452830188,\n",
       " 'tempo': 0.5613207547169812,\n",
       " 'politica': 0.5566037735849056,\n",
       " 'vez': 0.5471698113207547,\n",
       " 'diante': 0.5448113207547169,\n",
       " 'coisa': 0.5424528301886793,\n",
       " 'vai': 0.5377358490566038}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41f72289",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_urls = [f\"{pathlib.Path(os.path.abspath('README.md')).as_uri()}\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
