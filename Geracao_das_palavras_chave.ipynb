{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1203ec5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in c:\\users\\faradezo\\anaconda3\\lib\\site-packages (1.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Faradezo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\Faradezo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode\n",
    "\n",
    "import glob, os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from unidecode import unidecode\n",
    "import string\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "518fc383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files(folder):\n",
    "    file_list = []\n",
    "    if os.path.exists(folder):\n",
    "        for root, dirs, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                file_list.append(os.path.join(root,file))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ce412cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_stop_words(df_col):\n",
    "    #Faz a contagem de palavras por cada linha do artigo\n",
    "    df_col['words'] = df_col['texto'].str.split().str.len()\n",
    "    \n",
    "    #Elimina qualquer artigo que tenha gerado menos de 100 palavras\n",
    "    df_col = df_col.loc[(df_col['words'] > 100)]\n",
    "    \n",
    "    stop = stopwords.words('portuguese')\n",
    "    # stop.append('nao')\n",
    "    stop2 = list()\n",
    "    for word in stop:\n",
    "        stop2.append(unidecode(word))\n",
    "    \n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    # remoção de palavras de parada\n",
    "    #df_col['texto_tratado'] = df_col['texto'].apply(lambda x: [item for item in x if item not in stop])\n",
    "    df_col['texto_tratado'] = df_col['texto'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "    #Transforma em minuscula e remoção de acentos \n",
    "    df_col['texto_tratado'] = df_col['texto_tratado'].str.lower().apply(lambda x: unidecode(x))\n",
    "    # remocação de pontuaçao\n",
    "    df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
    "    # remocação de numeros\n",
    "    df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.digits), '')\n",
    "    # remoção de palavras de parada (repescagem)\n",
    "    df_col['texto_tratado'] = df_col['texto_tratado'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop2)]))\n",
    "    \n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    XCOL = vectorizer.fit_transform(df_col['texto_tratado'])\n",
    "    vocabulary_col = vectorizer.get_feature_names()\n",
    "    pdXCOL = pd.DataFrame(data=XCOL.toarray(), columns=vocabulary_col) #.iloc[:,0::2]\n",
    "    \n",
    "    \n",
    "    df_XCOL = pdXCOL.T\n",
    "    df_XCOL['total'] = df_XCOL.sum(axis=1) \n",
    "    \n",
    "    # Transpoe a matriz para que as palavras fiquem como linhas, e cada documento como uma linha\n",
    "    df_XCOL = pdXCOL.T\n",
    "    \n",
    "    #Calcula a quantidade de vezes que cada palavra é utilizada\n",
    "    df_XCOL['total'] = df_XCOL.sum(axis=1)\n",
    "    \n",
    "    #Remove as colunas individuais de cada documento para gerar a tabela\n",
    "    df_XCOL.drop(df_XCOL.columns[0:len(df_col['texto'])], axis=1, inplace=True)\n",
    "    \n",
    "    #Ordena o resultado final\n",
    "    df_XCOL = df_XCOL.sort_values(by='total', ascending=False)\n",
    "    #return df_XCOL <- até aqui tava indo\n",
    "    \n",
    "    n_words = 30\n",
    "    \n",
    "    # Transpoe a matriz para que as palavras fiquem como linhas, e cada documento como uma linha\n",
    "    pdXCOLT = pdXCOL.T\n",
    "    \n",
    "    #Mantem o percentual de frequencia de uso para comparação\n",
    "    pdXCOLT['presente'] = (pdXCOLT.ne(0).sum(axis=1) -1) / len(df_col['texto'])\n",
    "    \n",
    "    #Ordena\n",
    "    pdXCOLT = pdXCOLT.sort_values(by='presente', ascending=False)\n",
    "    \n",
    "    #Mantem so as 30 primeiras palavras\n",
    "    pdXCOLT = pdXCOLT.head(n_words)\n",
    "    \n",
    "    # Apaga todas as clunas, exceto a com as palavras\n",
    "    pdXCOLT.drop(pdXCOLT.columns[0:], axis=1, inplace=True)\n",
    "    \n",
    "    # Apaga todas as clunas, exceto a com as porcentagens presente\n",
    "    #pdXCOLT.drop(pdXCOLT.columns[0:-1], axis=1, inplace=True)\n",
    "    \n",
    "    #gera o dicionario com o saco de palavras\n",
    "    #ret = {}\n",
    "    #for sac in pdXCOLT.to_dict().values():\n",
    "    #    print(sac)\n",
    "    #    ret = sac\n",
    "\n",
    "    return pdXCOLT#ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5117e0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexandre_garcia.json\n",
      "arnaldo_jabor.json\n",
      "Carla_Araujo.json\n",
      "Josias_de_Souza.json\n",
      "Juca_Kfouri.json\n",
      "Kennedy_Alencar.json\n",
      "Leonardo_Sakamoto.json\n",
      "Mauricio_Stycer.json\n",
      "Reinaldo_Azevedo.json\n",
      "Ricardo_Kotscho.json\n",
      "Tales_Faria.json\n",
      "Thays_Oyama.json\n",
      "Walter_Maierovitch.json\n"
     ]
    }
   ],
   "source": [
    "#lista dos colunistas disponiveis\n",
    "for enu, colunista in enumerate(colunistas):\n",
    "    print(colunista[7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7abdcbcb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_1516/3207719678.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_col['texto_tratado'] = df_col['texto'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_1516/3207719678.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_col['texto_tratado'] = df_col['texto_tratado'].str.lower().apply(lambda x: unidecode(x))\n",
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_1516/3207719678.py:22: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_1516/3207719678.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_1516/3207719678.py:24: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.digits), '')\n",
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_1516/3207719678.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_col['texto_tratado'] = df_col['texto_tratado'].str.replace('[{}]'.format(string.digits), '')\n",
      "C:\\Users\\Faradezo\\AppData\\Local\\Temp/ipykernel_1516/3207719678.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_col['texto_tratado'] = df_col['texto_tratado'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop2)]))\n"
     ]
    }
   ],
   "source": [
    "sdp = {}\n",
    "#variavel com o nome de todos os arquivos json dos colunistas q estao salvos\n",
    "colunistas = get_all_files('textos')\n",
    "for enu, colunista in enumerate(colunistas):\n",
    "    link = (f'https://raw.githubusercontent.com/Faradezo/Reconhece_autor/main/textos/{colunista[7:]}')\n",
    "    df_col = pd.read_json(link)\n",
    "    b = get_all_stop_words(df_col)\n",
    "    if colunista[7:-5] not in sdp.keys():\n",
    "        sdp[colunista[7:-5]] = b.T.columns.tolist()\n",
    "sdp_file = open(\"sdp.pkl\", \"wb\")\n",
    "pickle.dump(sdp, sdp_file)\n",
    "sdp_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c6c9aeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alexandre_garcia': ['presidente', 'pais', 'anos', 'ainda', 'ser', 'agora', 'porque', 'sobre', 'vai', 'brasil', 'poder', 'contra', 'todos', 'ano', 'bolsonaro', 'governo', 'ter', 'maior', 'pode', 'assim', 'povo', 'semana', 'constituicao', 'quase', 'lei', 'brasileiros', 'milhoes', 'apenas', 'ministro', 'corrupcao'], 'arnaldo_jabor': ['tudo', 'ser', 'hoje', 'grande', 'mundo', 'vida', 'anos', 'pois', 'sempre', 'bem', 'nada', 'porque', 'pais', 'sobre', 'contra', 'ainda', 'assim', 'outro', 'onde', 'dia', 'agora', 'brasil', 'nunca', 'todos', 'tempo', 'politica', 'vez', 'diante', 'coisa', 'vai'], 'Carla_Araujo': ['presidente', 'bolsonaro', 'jair', 'ministro', 'feira', 'governo', 'nesta', 'economia', 'paulo', 'guedes', 'disse', 'coluna', 'federal', 'ministerio', 'afirmou', 'brasil', 'ainda', 'vai', 'tribunal', 'camara', 'congresso', 'segunda', 'ser', 'decisao', 'emergencial', 'sobre', 'apos', 'ter', 'economica', 'segundo'], 'Josias_de_Souza': ['bolsonaro', 'presidente', 'ser', 'sobre', 'ministro', 'contra', 'governo', 'brasil', 'covid', 'federal', 'supremo', 'pandemia', 'cpi', 'disse', 'ainda', 'republica', 'saude', 'ministerio', 'planalto', 'tribunal', 'capitao', 'pais', 'pode', 'feira', 'dois', 'ter', 'apenas', 'tres', 'fazer', 'politica'], 'Juca_Kfouri': ['jogo', 'porque', 'tempo', 'gol', 'ser', 'segundo', 'primeiro', 'dois', 'contra', 'fez', 'minutos', 'time', 'futebol', 'ainda', 'paulo', 'jogos', 'bola', 'fazer', 'brasil', 'tres', 'flamengo', 'assim', 'vez', 'ter', 'apenas', 'melhor', 'lugar', 'deu', 'bem', 'menos'], 'Kennedy_Alencar': ['presidente', 'bolsonaro', 'brasil', 'ser', 'pais', 'sobre', 'contra', 'jair', 'governo', 'trump', 'hoje', 'ter', 'disse', 'politica', 'ouca', 'donald', 'estados', 'federal', 'ministro', 'pode', 'eua', 'pandemia', 'segundo', 'comentario', 'porque', 'estado', 'republica', 'ex', 'fim', 'maior'], 'Leonardo_Sakamoto': ['bolsonaro', 'presidente', 'governo', 'ser', 'jair', 'federal', 'brasil', 'covid', 'ter', 'nesta', 'ano', 'pandemia', 'sobre', 'pessoas', 'contra', 'pais', 'parte', 'dia', 'pode', 'porque', 'apos', 'apenas', 'afirmou', 'nacional', 'ainda', 'forma', 'vai', 'populacao', 'disse', 'conta'], 'Mauricio_Stycer': ['sobre', 'feira', 'programa', 'ser', 'globo', 'ainda', 'disse', 'nesta', 'ter', 'apos', 'publico', 'vai', 'emissora', 'brasil', 'tv', 'segundo', 'momento', 'bbb', 'dois', 'apresentador', 'anos', 'bem', 'fez', 'todos', 'dia', 'desta', 'tres', 'final', 'forma', 'neste'], 'Reinaldo_Azevedo': ['presidente', 'bolsonaro', 'ser', 'ainda', 'jair', 'contra', 'caso', 'sobre', 'pode', 'governo', 'porque', 'bem', 'claro', 'ministro', 'vai', 'entao', 'assim', 'dizer', 'segundo', 'pais', 'ter', 'ai', 'coisa', 'menos', 'hoje', 'supremo', 'brasil', 'fazer', 'agora', 'integra'], 'Ricardo_Kotscho': ['vida', 'segue', 'presidente', 'bolsonaro', 'governo', 'agora', 'ser', 'ainda', 'pais', 'brasil', 'pandemia', 'dia', 'tudo', 'todos', 'sobre', 'contra', 'vez', 'vai', 'feira', 'ter', 'hoje', 'pode', 'fazer', 'paulo', 'onde', 'tempo', 'anos', 'apenas', 'ministro', 'semana'], 'Tales_Faria': ['presidente', 'bolsonaro', 'governo', 'jair', 'ministro', 'contra', 'disse', 'camara', 'ser', 'congresso', 'republica', 'ex', 'ainda', 'agora', 'paulo', 'deputado', 'sobre', 'segundo', 'federal', 'dem', 'feira', 'planalto', 'pode', 'partido', 'blog', 'hoje', 'ter', 'lider', 'senado', 'rodrigo'], 'Thays_Oyama': ['presidente', 'bolsonaro', 'ex', 'jair', 'governo', 'ministro', 'ser', 'hoje', 'ter', 'sobre', 'agora', 'capitao', 'contra', 'pode', 'apenas', 'vez', 'ainda', 'federal', 'brasil', 'ontem', 'disse', 'caso', 'menos', 'paulo', 'republica', 'segundo', 'ano', 'bem', 'assim', 'parte'], 'Walter_Maierovitch': ['presidente', 'pano', 'rapido', 'republica', 'brasil', 'outro', 'bolsonaro', 'ter', 'supremo', 'ministro', 'federal', 'politica', 'onde', 'ainda', 'ser', 'tribunal', 'lei', 'ministros', 'apenas', 'poder', 'contra', 'caso', 'constitucional', 'sobre', 'governo', 'constituicao', 'politico', 'tempo', 'stf', 'usar']}\n"
     ]
    }
   ],
   "source": [
    "a_file = open(\"sdp.pkl\", \"rb\")\n",
    "output = pickle.load(a_file)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
